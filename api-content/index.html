{"posts":[{"title":"kubernetes学习笔记 -  Probe Manager","content":" 所有的相关代码，都基于kubernetes v1.19.3 1. 启动探测 kubelet负责周期性的调谐 Pod，在需要创建新的Pod 的时候，对每一个 Pod 增加一个探针来探测 Pod 的状态。 下面是启动代码 //kubelet/kubelet.go func (kl *Kubelet) HandlePodAdditions(pods []*v1.Pod) { start := kl.clock.Now() sort.Sort(sliceutils.PodsByCreationTime(pods)) for _, pod := range pods { existingPods := kl.podManager.GetPods() //增加到 podManager 中，以后查询 pod 都会从这里查 kl.podManager.AddPod(pod) //如果是镜像 Pod，他只是静态 Pod 的一个影子而已，不会参与增加，删除什么的 //对镜像 Pod 的操作，都只是对静态 Pod 的一次刷新而已 if kubetypes.IsMirrorPod(pod) { kl.handleMirrorPod(pod, start) continue } if !kl.podIsTerminated(pod) { activePods := kl.filterOutTerminatedPods(existingPods) //检查当前节点是否可以接受新的 Pod 申请 if ok, reason, message := kl.canAdmitPod(activePods, pod); !ok { kl.rejectPod(pod, reason, message) continue } } mirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod) //交给 worker 去处理 Pod 的新增事宜，这里暂且不关注 kl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start) //本章的重点，将新增的 Pod 加入到probeManager中去 **kl.probeManager.AddPod(pod)** } } 2. probeManager probeManager 主要对 Pod 进行可用性的探测， 具体来看AddPod是怎么处理的 //kubelet/probe/prober_manager.go func (m *manager) AddPod(pod *v1.Pod) { //因为可能同时要处理多个 pod，加锁 m.workerLock.Lock() defer m.workerLock.Unlock() key := probeKey{podUID: pod.UID} //获取所有的容器 for _, c := range pod.Spec.Containers { key.containerName = c.Name //如果支持StartupProbe if c.StartupProbe != nil &amp;&amp; utilfeature.DefaultFeatureGate.Enabled(features.StartupProbe) { key.probeType = startup if _, ok := m.workers[key]; ok { klog.Errorf(&quot;Startup probe already exists! %v - %v&quot;, format.Pod(pod), c.Name) return } w := newWorker(m, startup, pod, c) m.workers[key] = w go w.run() } //处理 ReadnessProbe if c.ReadinessProbe != nil { key.probeType = readiness if _, ok := m.workers[key]; ok { klog.Errorf(&quot;Readiness probe already exists! %v - %v&quot;, format.Pod(pod), c.Name) return } w := newWorker(m, readiness, pod, c) m.workers[key] = w go w.run() } //处理 LivenessProbe if c.LivenessProbe != nil { key.probeType = liveness if _, ok := m.workers[key]; ok { klog.Errorf(&quot;Liveness probe already exists! %v - %v&quot;, format.Pod(pod), c.Name) return } w := newWorker(m, liveness, pod, c) m.workers[key] = w go w.run() } } } 从代码上来看, probeManager 支持三种类型的探针: StartupProbe ReadnessProbe LivenessProbe 不管是什么类型的探针,最终都是为每个容器产生了一个新的 worker 来处理的. 3. worker 来看下 worker 是做什么用的 // kubelet/probe/worker.go func newWorker( m *manager, probeType probeType, pod *v1.Pod, container v1.Container) *worker { //构造一个 worker 对象 w := &amp;worker{ stopCh: make(chan struct{}, 1), // Buffer so stop() can be non-blocking. pod: pod, container: container, probeType: probeType, probeManager: m, } switch probeType { case readiness: w.spec = container.ReadinessProbe //探测的结果放到readnessManager中 w.resultsManager = m.readinessManager w.initialValue = results.Failure case liveness: w.spec = container.LivenessProbe //探测的结果放到livenessManager中 w.resultsManager = m.livenessManager w.initialValue = results.Success case startup: w.spec = container.StartupProbe //探测的结果放到startupManager中 w.resultsManager = m.startupManager w.initialValue = results.Unknown } ...... return w } 在构造 worker 的时候,不同类型的探针, 最终的探测结果交给了不同的 resultManager 去处理. 下面来看下他的 Run 方法是如何进行容器探测的 // kubelet/probe/worker.go func (w *worker) run() { probeTickerPeriod := time.Duration(w.spec.PeriodSeconds) * time.Second time.Sleep(time.Duration(rand.Float64() * float64(probeTickerPeriod))) //一个 ticker, 每隔一定的时间去探测一次 probeTicker := time.NewTicker(probeTickerPeriod) defer func() { // 如果关闭了 pod, 所有的探测都可以取消了 probeTicker.Stop() if !w.containerID.IsEmpty() { w.resultsManager.Remove(w.containerID) } w.probeManager.removeWorker(w.pod.UID, w.container.Name, w.probeType) ProberResults.Delete(w.proberResultsSuccessfulMetricLabels) ProberResults.Delete(w.proberResultsFailedMetricLabels) ProberResults.Delete(w.proberResultsUnknownMetricLabels) }() probeLoop: //每隔一定的时间去执行 doProbe 去探测,如果主动要求停止,则退出循环 for w.doProbe() { // Wait for next probe tick. select { case &lt;-w.stopCh: break probeLoop case &lt;-probeTicker.C: // continue } } } 探测的重点转移到了doProbe方法, 来看下具体的实现 // kubelet/probe/worker.go func (w *worker) doProbe() (keepGoing bool) { defer func() { recover() }() // Actually eat panics (HandleCrash takes care of logging) defer runtime.HandleCrash(func(_ interface{}) { keepGoing = true }) //获取 pod 的状态,获取不到就继续下一次循环 status, ok := w.probeManager.statusManager.GetPodStatus(w.pod.UID) if !ok { return true } //如果 Pod 关闭了或者终止了,那么探测器或者也没用,就不探测了,返回 false 自动终止 if status.Phase == v1.PodFailed || status.Phase == v1.PodSucceeded { return false } //获取容器的状态,如果不存在,继续等着 c, ok := podutil.GetContainerStatus(status.ContainerStatuses, w.container.Name) if !ok || len(c.ContainerID) == 0 { return true // Wait for more information. } //这里重点说明一下是什么意思 //Pod 探测容器的状态,如果容器启动不成功,kubelet 会尝试重启 Pod, 会重新分配一个容器的 ID, //但是 worker 只有一个, 如果容器的 ID 和之前不一致了,说明了什么? 说明了容器被重启了,那么这里 //需要设置onHold=false,表示我这个 worker 需要等待新的容器启动完成了,我再开启探测它, 别人家还 //没有启动呢,我就拼命的探测,一探测说人家挂了,又重启,还没等到人家起来呢,又探测又重启,无休止的循环了 //所以这里等待一下容器启动完成之后再进行探测. if w.containerID.String() != c.ContainerID { if !w.containerID.IsEmpty() { w.resultsManager.Remove(w.containerID) } w.containerID = kubecontainer.ParseContainerID(c.ContainerID) w.resultsManager.Set(w.containerID, w.initialValue, w.pod) // We've got a new container; resume probing. **w.onHold = false** } if w.onHold { //worker 在等待,直到新的容器创建成功 return true } if c.State.Running == nil { //不是运行状态的容器 if !w.containerID.IsEmpty() { //直接给他的状态设置为 Failure w.resultsManager.Set(w.containerID, results.Failure, w.pod) } // 如果容器不需要被重启的话,直接不探测了,返回 false 就可以了 return c.State.Terminated == nil || w.pod.Spec.RestartPolicy != v1.RestartPolicyNever } //启动之后不会立刻探测,有可能人家还没有准备好, 等待一定的时间之后再去真正的探测 if int32(time.Since(c.State.Running.StartedAt.Time).Seconds()) &lt; w.spec.InitialDelaySeconds { return true } if c.Started != nil &amp;&amp; *c.Started { // 如果容器已经起来了并且通过了探针探测, 停止 startup的探测 if w.probeType == startup { return true } } else { // 如果容器尚未启动完成, 那么其他的探测器就先等等再探测,返回 true 表示等下一个周期再来 if w.probeType != startup { return true } } //执行探测逻辑 result, err := w.probeManager.prober.probe(w.probeType, w.pod, status, w.container, w.containerID) if err != nil { //失败了继续探测 return true } ...... if (result == results.Failure &amp;&amp; w.resultRun &lt; int(w.spec.FailureThreshold)) || (result == results.Success &amp;&amp; w.resultRun &lt; int(w.spec.SuccessThreshold)) { //探测一次不认为是成功或者失败,要多探测几次,达到阈值之后才可以认为有结果了,这里持续探测 return true } //把探测的结果写到resultManager中,不同的探针有不同的 resultManager w.resultsManager.Set(w.containerID, result, w.pod) if (w.probeType == liveness || w.probeType == startup) &amp;&amp; result == results.Failure { // 容器探活探针探测失败的话,他将会被重启, 停止当前的探测,直到新的容器重新被拉起 w.onHold = true w.resultRun = 0 } return true } doProbe 主要做了几件事情: 根据状态判断是否要持续探测 执行探测逻辑 , 探测一定的次数, 需要等到阈值满足之后才认为有了结果 把结果写到 resultManager 中,供别人使用. 真正的探测逻辑其实比较简单,如下 //kubelet/prober/probe.go func (pb *prober) probe(probeType probeType, pod *v1.Pod, status v1.PodStatus, container v1.Container, containerID kubecontainer.ContainerID) (results.Result, error) { var probeSpec *v1.Probe //根据不同的探测, 设置不同的探测方法 switch probeType { case readiness: probeSpec = container.ReadinessProbe case liveness: probeSpec = container.LivenessProbe case startup: probeSpec = container.StartupProbe default: return results.Failure, fmt.Errorf(&quot;unknown probe type: %q&quot;, probeType) } ctrName := fmt.Sprintf(&quot;%s:%s&quot;, format.Pod(pod), container.Name) if probeSpec == nil { klog.Warningf(&quot;%s probe for %s is nil&quot;, probeType, ctrName) return results.Success, nil } //开启探测逻辑, 这里带有 5 次重试,失败了自己循环探测 result, output, err := pb.runProbeWithRetries(probeType, probeSpec, pod, status, container, containerID, maxProbeRetries) if err != nil || (result != probe.Success &amp;&amp; result != probe.Warning) { // Probe failed in one way or another. if err != nil { klog.V(1).Infof(&quot;%s probe for %q errored: %v&quot;, probeType, ctrName, err) pb.recordContainerEvent(pod, &amp;container, v1.EventTypeWarning, events.ContainerUnhealthy, &quot;%s probe errored: %v&quot;, probeType, err) } else { // result != probe.Success klog.V(1).Infof(&quot;%s probe for %q failed (%v): %s&quot;, probeType, ctrName, result, output) pb.recordContainerEvent(pod, &amp;container, v1.EventTypeWarning, events.ContainerUnhealthy, &quot;%s probe failed: %s&quot;, probeType, output) } return results.Failure, err } if result == probe.Warning { pb.recordContainerEvent(pod, &amp;container, v1.EventTypeWarning, events.ContainerProbeWarning, &quot;%s probe warning: %s&quot;, probeType, output) klog.V(3).Infof(&quot;%s probe for %q succeeded with a warning: %s&quot;, probeType, ctrName, output) } else { klog.V(3).Infof(&quot;%s probe for %q succeeded&quot;, probeType, ctrName) } return results.Success, nil } //kubelet/prober/probe.go func (pb *prober) runProbe(probeType probeType, p *v1.Probe, pod *v1.Pod, status v1.PodStatus, container v1.Container, containerID kubecontainer.ContainerID) (probe.Result, string, error) { timeout := time.Duration(p.TimeoutSeconds) * time.Second //如果是 exec 模式,就是在容器里执行一个命令,返回执行的结果 if p.Exec != nil { klog.V(4).Infof(&quot;Exec-Probe Pod: %v, Container: %v, Command: %v&quot;, pod.Name, container.Name, p.Exec.Command) command := kubecontainer.ExpandContainerCommandOnlyStatic(p.Exec.Command, container.Env) return pb.exec.Probe(pb.newExecInContainer(container, containerID, command, timeout)) } //如果是 http 模式,执行 http 调用,返回 code if p.HTTPGet != nil { scheme := strings.ToLower(string(p.HTTPGet.Scheme)) host := p.HTTPGet.Host if host == &quot;&quot; { host = status.PodIP } port, err := extractPort(p.HTTPGet.Port, container) if err != nil { return probe.Unknown, &quot;&quot;, err } path := p.HTTPGet.Path klog.V(4).Infof(&quot;HTTP-Probe Host: %v://%v, Port: %v, Path: %v&quot;, scheme, host, port, path) url := formatURL(scheme, host, port, path) headers := buildHeader(p.HTTPGet.HTTPHeaders) klog.V(4).Infof(&quot;HTTP-Probe Headers: %v&quot;, headers) switch probeType { case liveness: return pb.livenessHTTP.Probe(url, headers, timeout) case startup: return pb.startupHTTP.Probe(url, headers, timeout) default: return pb.readinessHTTP.Probe(url, headers, timeout) } } //如果是 tcp 探测,直接拨号,返回探测结果即可 if p.TCPSocket != nil { port, err := extractPort(p.TCPSocket.Port, container) if err != nil { return probe.Unknown, &quot;&quot;, err } host := p.TCPSocket.Host if host == &quot;&quot; { host = status.PodIP } klog.V(4).Infof(&quot;TCP-Probe Host: %v, Port: %v, Timeout: %v&quot;, host, port, timeout) return pb.tcp.Probe(host, port, timeout) } klog.Warningf(&quot;Failed to find probe builder for container: %v&quot;, container) return probe.Unknown, &quot;&quot;, fmt.Errorf(&quot;missing probe handler for %s:%s&quot;, format.Pod(pod), container.Name) } 综上, 探针有三种不同的探测方式 Exec 表示在容器内执行一个命令,返回执行的结果 Http 表示执行一个 http 请求,返回码来决定成功还是失败 Tcp 表示执行一个拨号,拨通了就认为是成功了 4. resultManager 上文描述了探针是如何执行的, 执行后的结果都收集到了对应的 resultManager 中, 类型如下: readinessManager livenessManager startupManager 下面针对这三种探针的处理方式, 展开叙述 4.1 livenessManager 这种类型的探针, 称为探活探针, 意思是, 探测的结果, 直接决定着 Pod 的生死, 如果探测失败了, kubelet 将会重启它. //kubelet/prober/results/results_manager.go func (m *manager) Set(id kubecontainer.ContainerID, result Result, pod *v1.Pod) { if m.setInternal(id, result) { m.updates &lt;- Update{id, result, pod.UID} } } 设置容器的探测结果, 其实就是把一个 Update结构体, 放入了updates的 channel 中去. 有人放,肯定有人读, 那么谁读了呢? kubelet 去读, 来看代码 //kubelet/kubelet.go // 截取syncLoopIteration方法, 大循环中的一部分,具体代码分析见 kubelet 启动篇 case update := &lt;-kl.livenessManager.Updates(): if update.Result == proberesults.Failure { // The liveness manager detected a failure; sync the pod. // We should not use the pod from livenessManager, because it is never updated after // initialization. pod, ok := kl.podManager.GetPodByUID(update.PodUID) if !ok { // If the pod no longer exists, ignore the update. klog.V(4).Infof(&quot;SyncLoop (container unhealthy): ignore irrelevant update: %#v&quot;, update) break } klog.V(1).Infof(&quot;SyncLoop (container unhealthy): %q&quot;, format.Pod(pod)) handler.HandlePodSyncs([]*v1.Pod{pod}) } kubelet 启动之后, 会从livenessManager的探测结果中读取 Update , 如果有容器失败了, 那么会获取这个容器对应的 Pod, 然后调用HandlePodSyncs方法, 杀死这个 pod,然后重新拉起一个新的 Pod. 具体的代码见 kubelet, 这里不再展开了. 4.2 readnessManager 这种类型的探针,称为就绪探针, 意思是, 当容器准备好了,可以接受请求了, 比如 service 就是在就绪探针有了结果的情况下, 才会把流量转发到 Pod 中来. 不然没有就绪就转发流量,可能会造成流量丢失. 在prober_manager启动的时候, 执行了以下逻辑 //kubelet/prober/prober_manager.go func (m *manager) Start() { // Start syncing readiness. go wait.Forever(m.updateReadiness, 0) // Start syncing startup. go wait.Forever(m.updateStartup, 0) } 启动了两个循环, 不停的探测updateReadiness 和 updateStartup , 下面来看 updateReadiness是如何处理的 //kubelet/prober/prober_manager.go func (m *manager) updateReadiness() { //从channel 中获取状态变化 update := &lt;-m.readinessManager.Updates() //获取状态 ready := update.Result == results.Success //通过statusManager设置状态 , 交给了statusManager去处理. 具体的见statusManager逻辑 m.statusManager.SetContainerReadiness(update.PodUID, update.ContainerID, ready) } 从上诉代码来看, 就绪探针把容器的探测结果, 统一交给了statusManager来处理. 具体的逻辑见statusManager. 简单来说就是把状态更新到 etcd, 然后 service 会根据状态来做进一步的判断. 4.3 startupManager 和readiness处理逻辑几乎一致, 不展开叙述 //kubelet/prober/prober_manager.go func (m *manager) updateStartup() { update := &lt;-m.startupManager.Updates() started := update.Result == results.Success m.statusManager.SetContainerStartup(update.PodUID, update.ContainerID, started) } 5. 总结 livenessProbe 用来探活, 检查容器是否还在运行, 可以为 pod 中的每个容器设置存活探针. 如果探测失败, kubernetes 将定期的执行探针并重新启动容器 readiniessProbe 就绪探针用来确定, 特定的 pod 是否可以接受客户端的请求, 当容器就绪探针返回成功时, 表示容器已经准备好接受请求了. 启动容器时，可以为Kubernetes配置一个等待时间，经过等待时间后才可以执行第一次准备就绪检查。之后，它会周期性地调用探针，并根据就绪探针的结果采取行动。如果某个pod报告它尚未准备就绪，则会从该服务中删除该pod。如果pod再次准备就绪，则重新添加pod。与存活探针不同，如果容器未通过准备检查，则不会被终止或重新启动。这是存活探针与就绪探针之间的重要区别。存活探针通过杀死异常的容器并用新的正常容器替代它们来保持pod正常工作，而就绪探针确保只有准备好处理请求的pod才可以接收它们（请求）。这在容器启动时最为必要，当然在容器运行一段时间后也是有用的。 探针支持是三种探测容器的机制 Http Get 探针对容器的 IP 地址(自己指定的端口和路径) 执行 Http Get 请求, 如果探测成功, 且响应代码不代表错误, 则认为探测成功, 否则认为失败,容器将被重新启动 Tcp套接字尝试与容器指定的端口建立 tcp 连接,如果连接建立成功,探测成功 Exec 在容器内执行任意命令,并检查命令的退出状态码, 如果状态码是 0 , 表示探测成功. 其他被认为探测失败 ","link":"http://kzltime.cn/post/kubernetes-probe-manager/"},{"title":"Kubernetes学习笔记 - Volume Manager","content":" 所有的相关代码，都基于kubernetes v1.19.3 1. 运行原理 kubelet启动时会调用volumeMananger的 Run 方法启动卷管理器。 它负责在当前节点的 Pod 和 Volume 发生变化的时候，对 Volume 进行挂载和卸载等操作。 func (vm *volumeManager) Run(sourcesReady config.SourcesReady, stopCh &lt;-chan struct{}) { defer runtime.HandleCrash() go vm.desiredStateOfWorldPopulator.Run(sourcesReady, stopCh) go vm.reconciler.Run(stopCh) metrics.Register(vm.actualStateOfWorld, vm.desiredStateOfWorld, vm.volumePluginMgr) if vm.kubeClient != nil { vm.volumePluginMgr.Run(stopCh) } &lt;-stopCh klog.Infof(&quot;Shutting down Kubelet Volume Manager&quot;) } 主要做两件事情 desiredStateOfWorldPopulator主要负责从 API server 中获取 Pod 的信息，将他们更新到本地的一个DesiredStateOfWorld的数据结构中。 reconciler 负责调谐，也就是根据DesiredStateOfWorld 的状态变更，更新实际的挂载信息。 在 Pod 的启动过程中，如果需要挂载卷，则首先等待卷挂载完成之后，才可以继续向下进行。 2. DesiredStateOfWorld 执行一个大循环， 做的事情大致也有两个 findAndAddNewPods findAndRemoveDeletedPods 通过以上两个方法，分别获取节点中被添加的新 Pod 或者已经删除的老的 Pod，获取到 Pod 之后会根据当前的状态修改期望状态 findAndAddNewPods //kubelet/volumemanager/populator/desired_state_of_world_populator.go func (dswp *desiredStateOfWorldPopulator) findAndAddNewPods() { // Map unique pod name to outer volume name to MountedVolume. mountedVolumesForPod := make(map[volumetypes.UniquePodName]map[string]cache.MountedVolume) ...... processedVolumesForFSResize := sets.NewString() //获取所有的 pod 数据 for _, pod := range dswp.podManager.GetPods() { //如果是终止的 pod，不用挂载卷 if dswp.isPodTerminated(pod) { continue } //处理特定的 pod 的卷信息，把他们放到一个desired state的数据结构里去 dswp.processPodVolumes(pod, mountedVolumesForPod, processedVolumesForFSResize) } } func (dswp *desiredStateOfWorldPopulator) processPodVolumes( pod *v1.Pod, mountedVolumesForPod map[volumetypes.UniquePodName]map[string]cache.MountedVolume, processedVolumesForFSResize sets.String) { if pod == nil { return } //获取 pod 的UID uniquePodName := util.GetUniquePodName(pod) //在当前processedPods中缓存有这个 pod 的信息，就不处理了 if dswp.podPreviouslyProcessed(uniquePodName) { return } allVolumesAdded := true mounts, devices := util.GetPodVolumeNames(pod) expandInUsePV := utilfeature.DefaultFeatureGate.Enabled(features.ExpandInUsePersistentVolumes) // 从 Pod 的定义中拿到所有的待绑定的卷信息 for _, podVolume := range pod.Spec.Volumes { if !mounts.Has(podVolume.Name) &amp;&amp; !devices.Has(podVolume.Name) { continue } //创建卷信息, 后续再具体分析这个代码 pvc, volumeSpec, volumeGidValue, err := dswp.createVolumeSpec(podVolume, pod, mounts, devices) if err != nil { dswp.desiredStateOfWorld.AddErrorToPod(uniquePodName, err.Error()) allVolumesAdded = false continue } // 把卷信息添加到数据结构中 _, err = dswp.desiredStateOfWorld.AddPodToVolume( uniquePodName, pod, volumeSpec, podVolume.Name, volumeGidValue) if err != nil { dswp.desiredStateOfWorld.AddErrorToPod(uniquePodName, err.Error()) allVolumesAdded = false } else { } if expandInUsePV { dswp.checkVolumeFSResize(pod, podVolume, pvc, volumeSpec, uniquePodName, mountedVolumesForPod, processedVolumesForFSResize) } } //如果所有的卷都处理完毕了，标记处理完成 if allVolumesAdded { dswp.markPodProcessed(uniquePodName) // New pod has been synced. Re-mount all volumes that need it // (e.g. DownwardAPI) dswp.actualStateOfWorld.MarkRemountRequired(uniquePodName) // Remove any stored errors for the pod, everything went well in this processPodVolumes dswp.desiredStateOfWorld.PopPodErrors(uniquePodName) } else if dswp.podHasBeenSeenOnce(uniquePodName) { // For the Pod which has been processed at least once, even though some volumes // may not have been reprocessed successfully this round, we still mark it as processed to avoid // processing it at a very high frequency. The pod will be reprocessed when volume manager calls // ReprocessPod() which is triggered by SyncPod. dswp.markPodProcessed(uniquePodName) } } 做的主要的事情就是将节点加入的新 Pod 添加到DesiredStateOfWorld 中。 findAndRemoveDeletedPods func (dswp *desiredStateOfWorldPopulator) findAndRemoveDeletedPods() { var runningPods []*kubecontainer.Pod runningPodsFetched := false for _, volumeToMount := range dswp.desiredStateOfWorld.GetVolumesToMount() { pod, podExists := dswp.podManager.GetPodByUID(volumeToMount.Pod.UID) if podExists { // Skip running pods if !dswp.isPodTerminated(pod) { continue } if dswp.keepTerminatedPodVolumes { continue } } // Once a pod has been deleted from kubelet pod manager, do not delete // it immediately from volume manager. Instead, check the kubelet // containerRuntime to verify that all containers in the pod have been // terminated. if !runningPodsFetched { var getPodsErr error runningPods, getPodsErr = dswp.kubeContainerRuntime.GetPods(false) if getPodsErr != nil { klog.Errorf( &quot;kubeContainerRuntime.findAndRemoveDeletedPods returned error %v.&quot;, getPodsErr) continue } runningPodsFetched = true dswp.timeOfLastGetPodStatus = time.Now() } runningContainers := false for _, runningPod := range runningPods { if runningPod.ID == volumeToMount.Pod.UID { if len(runningPod.Containers) &gt; 0 { runningContainers = true } break } } if runningContainers { klog.V(4).Infof( &quot;Pod %q still has one or more containers in the non-exited state. Therefore, it will not be removed from desired state.&quot;, format.Pod(volumeToMount.Pod)) continue } exists, _, _ := dswp.actualStateOfWorld.PodExistsInVolume(volumeToMount.PodName, volumeToMount.VolumeName) if !exists &amp;&amp; podExists { klog.V(4).Infof( volumeToMount.GenerateMsgDetailed(fmt.Sprintf(&quot;Actual state has not yet has this volume mounted information and pod (%q) still exists in pod manager, skip removing volume from desired state&quot;, format.Pod(volumeToMount.Pod)), &quot;&quot;)) continue } klog.V(4).Infof(volumeToMount.GenerateMsgDetailed(&quot;Removing volume from desired state&quot;, &quot;&quot;)) dswp.desiredStateOfWorld.DeletePodFromVolume( volumeToMount.PodName, volumeToMount.VolumeName) dswp.deleteProcessedPod(volumeToMount.PodName) } podsWithError := dswp.desiredStateOfWorld.GetPodsWithErrors() for _, podName := range podsWithError { if _, podExists := dswp.podManager.GetPodByUID(types.UID(podName)); !podExists { dswp.desiredStateOfWorld.PopPodErrors(podName) } } } 总而言之，这俩的目的就是将当前节点的期望状态，同步到DesiredStateOfWorld中，等待有人处理这个数据结构。 类似于生产者 3. Reconciler 负责对当前节点上的 Volume 进行管理，启动一个reconcile循环 ， 在方法中分三次对当前状态和期望转改不匹配的卷，进行卸载，挂载等操作。 //kubelet/volumemanager/reconciler/reconciler.go func (rc *reconciler) reconciliationLoopFunc() func() { return func() { rc.reconcile() if rc.populatorHasAddedPods() &amp;&amp; !rc.StatesHasBeenSynced() { rc.sync() } } } 其中 sync 方法，最终还是调用到了reconcile方法，具体来看代码 //kubelet/volumemanager/reconciler/reconciler.go func (rc *reconciler) reconcile() { //首先保证应该被卸载的，但是依然在节点中存在卷被卸载，比如删除了 Pod 这种情况 rc.unmountVolumes() // 将应该挂载的卷，挂载到合适的位置 rc.mountAttachVolumes() //将***设备***与节点分离或者卸载， 这个设备比如是 CDROM等 device rc.unmountDetachDevices() } unmountVolumes //kubelet/volumemanager/reconciler/reconciler.go func (rc *reconciler) unmountVolumes() { //遍历当前节点中所有的挂载信息 for _, mountedVolume := range rc.actualStateOfWorld.GetAllMountedVolumes() { if !rc.desiredStateOfWorld.PodExistsInVolume(mountedVolume.PodName, mountedVolume.VolumeName) { //如果不在期望里面，说明是要被卸载的,执行卸载动作 err := rc.operationExecutor.UnmountVolume( mountedVolume.MountedVolume, rc.actualStateOfWorld, rc.kubeletPodsDir) if err != nil &amp;&amp; !nestedpendingoperations.IsAlreadyExists(err) &amp;&amp; !exponentialbackoff.IsExponentialBackoff(err) { // Ignore nestedpendingoperations.IsAlreadyExists and exponentialbackoff.IsExponentialBackoff errors, they are expected. // Log all other errors. klog.Errorf(mountedVolume.GenerateErrorDetailed(fmt.Sprintf(&quot;operationExecutor.UnmountVolume failed (controllerAttachDetachEnabled %v)&quot;, rc.controllerAttachDetachEnabled), err).Error()) } if err == nil { klog.Infof(mountedVolume.GenerateMsgDetailed(&quot;operationExecutor.UnmountVolume started&quot;, &quot;&quot;)) } } } } mountAttachVolumes //kubelet/volumemanager/reconciler/reconciler.go func (rc *reconciler) mountAttachVolumes() { //获取所有期望的卷挂载信息 for _, volumeToMount := range rc.desiredStateOfWorld.GetVolumesToMount() { volMounted, devicePath, err := rc.actualStateOfWorld.PodExistsInVolume(volumeToMount.PodName, volumeToMount.VolumeName) //这里得到的是，本机 Node 节点的实际目录，后续是将这个目录，挂载到 Pod 中。 **volumeToMount.DevicePath = devicePath** if cache.IsVolumeNotAttachedError(err) { // 如果实际中卷没法挂载，原因是并没有 attach，先把卷Attach 到本机 node 上 if rc.controllerAttachDetachEnabled || !volumeToMount.PluginIsAttachable { ....... } else { //处理 Volume 的 Attach，为什么需要 Attach，是因为某些类型的卷，必须挂载到 //本机的节点才可以被使用，比如 google 的 GCE，且只能Attach 到一台机器 //后面会具体介绍 volumeToAttach := operationexecutor.VolumeToAttach{ VolumeName: volumeToMount.VolumeName, VolumeSpec: volumeToMount.VolumeSpec, NodeName: rc.nodeName, } klog.V(5).Infof(volumeToAttach.GenerateMsgDetailed(&quot;Starting operationExecutor.AttachVolume&quot;, &quot;&quot;)) err := rc.operationExecutor.AttachVolume(volumeToAttach, rc.actualStateOfWorld) ....... } } else if !volMounted || cache.IsRemountRequiredError(err) { //需要重新挂载, 具体的挂载是在这里展开的 remountingLogStr := &quot;&quot; isRemount := cache.IsRemountRequiredError(err) err := rc.operationExecutor.MountVolume( rc.waitForAttachTimeout, volumeToMount.VolumeToMount, rc.actualStateOfWorld, isRemount) ..... } else if cache.IsFSResizeRequiredError(err) &amp;&amp; //纵向扩展卷信息，比如增加大小什么的 err := rc.operationExecutor.ExpandInUseVolume( volumeToMount.VolumeToMount, rc.actualStateOfWorld) ............ } } unmountDetachDeives //kubelet/volumemanager/reconciler/reconciler.go func (rc *reconciler) unmountDetachDevices() { //遍历当前节点实际已经Attach的卷，但是没有挂载到 POD上的 for _, attachedVolume := range rc.actualStateOfWorld.GetUnmountedVolumes() { // 如果需要调谐 if !rc.desiredStateOfWorld.VolumeExists(attachedVolume.VolumeName) &amp;&amp; !rc.operationExecutor.IsOperationPending(attachedVolume.VolumeName, nestedpendingoperations.EmptyUniquePodName, nestedpendingoperations.EmptyNodeName) { //如果设备已经挂载了，卸载 if attachedVolume.DeviceMayBeMounted() { // Volume is globally mounted to device, unmount it err := rc.operationExecutor.UnmountDevice( attachedVolume.AttachedVolume, rc.actualStateOfWorld, rc.hostutil) ...... } else { // 卷已经Attach到节点上了，Detach它 if rc.controllerAttachDetachEnabled || !attachedVolume.PluginIsAttachable { rc.actualStateOfWorld.MarkVolumeAsDetached(attachedVolume.VolumeName, attachedVolume.NodeName) } else { //detach err := rc.operationExecutor.DetachVolume( attachedVolume.AttachedVolume, false /* verifySafeToDetach */, rc.actualStateOfWorld) ...... } } } } 本篇主要讨论挂载Mount 的事情，重点来看 MountVolume 是怎么进行的. 从上面代码来看，挂载的操作交由了 operationExecutor 来执行的。 4. operationExecutor operationExecutor 是本reconciler的一个属性, 指向了OperationExecutor的一个接口，主要功能如下 //volume/util/operationexecutor/operation_executor.go type OperationExecutor interface { //附着卷 AttachVolume(volumeToAttach VolumeToAttach, actualStateOfWorld ActualStateOfWorldAttacherUpdater) error VerifyVolumesAreAttachedPerNode(AttachedVolumes []AttachedVolume, nodeName types.NodeName, actualStateOfWorld ActualStateOfWorldAttacherUpdater) error VerifyVolumesAreAttached(volumesToVerify map[types.NodeName][]AttachedVolume, actualStateOfWorld ActualStateOfWorldAttacherUpdater) //解附着 DetachVolume(volumeToDetach AttachedVolume, verifySafeToDetach bool, actualStateOfWorld ActualStateOfWorldAttacherUpdater) error //挂载卷 MountVolume(waitForAttachTimeout time.Duration, volumeToMount VolumeToMount, actualStateOfWorld ActualStateOfWorldMounterUpdater, isRemount bool) error //解挂 UnmountVolume(volumeToUnmount MountedVolume, actualStateOfWorld ActualStateOfWorldMounterUpdater, podsDir string) error //设备解挂 UnmountDevice(deviceToDetach AttachedVolume, actualStateOfWorld ActualStateOfWorldMounterUpdater, hostutil hostutil.HostUtils) error VerifyControllerAttachedVolume(volumeToMount VolumeToMount, nodeName types.NodeName, actualStateOfWorld ActualStateOfWorldAttacherUpdater) error IsOperationPending(volumeName v1.UniqueVolumeName, podName volumetypes.UniquePodName, nodeName types.NodeName) bool ExpandInUseVolume(volumeToMount VolumeToMount, actualStateOfWorld ActualStateOfWorldMounterUpdater) error ReconstructVolumeOperation(volumeMode v1.PersistentVolumeMode, plugin volume.VolumePlugin, mapperPlugin volume.BlockVolumePlugin, uid types.UID, podName volumetypes.UniquePodName, volumeSpecName string, volumePath string, pluginName string) (*volume.Spec, error) CheckVolumeExistenceOperation(volumeSpec *volume.Spec, mountPath, volumeName string, mounter mount.Interface, uniqueVolumeName v1.UniqueVolumeName, podName volumetypes.UniquePodName, podUID types.UID, attachable volume.AttachableVolumePlugin) (bool, error) } 具体来看MountVolume是如何实现的 //volume/util/operationexecutor/operation_executor.go func (oe *operationExecutor) MountVolume( waitForAttachTimeout time.Duration, volumeToMount VolumeToMount, actualStateOfWorld ActualStateOfWorldMounterUpdater, isRemount bool) error { //获取当前卷是什么类型的卷 fsVolume, err := util.CheckVolumeModeFilesystem(volumeToMount.VolumeSpec) if err != nil { return err } var generatedOperations volumetypes.GeneratedOperations if fsVolume { //如果是文件系统，那么返回一个文件系统用的函数 generatedOperations = oe.operationGenerator.GenerateMountVolumeFunc( waitForAttachTimeout, volumeToMount, actualStateOfWorld, isRemount) } else { //如果是块设备，返回块设备的挂载函数 generatedOperations, err = oe.operationGenerator.GenerateMapVolumeFunc( waitForAttachTimeout, volumeToMount, actualStateOfWorld) } if err != nil { return err } podName := nestedpendingoperations.EmptyUniquePodName //开始挂载，最终执行，是用上面返回的两个函数来进行的 return oe.pendingOperations.Run( volumeToMount.VolumeName, podName, &quot;&quot; /* nodeName */, generatedOperations) } 文件系统和块设备有什么不同？ 文件系统是 linux 在块设备之上封装了一层通用的接口，可能会涉及到文件缓存之类的，块设备更靠近于底层，比如数据库这样的软件，可以直接通过操作块设备来进行存储，绕过操作系统的缓存。 GenerateMountVolumeFunc 用来处理挂载文件系统的 GenerateMapVolumeFunc 用来处理块设备的，把 device 映射一下 来看MountVolume的 Func //volume/util/operationexecutor/operation_generator.go func (og *operationGenerator) GenerateMountVolumeFunc( waitForAttachTimeout time.Duration, volumeToMount VolumeToMount, actualStateOfWorld ActualStateOfWorldMounterUpdater, isRemount bool) volumetypes.GeneratedOperations { //从当前的插件体系中，获取到这个卷对应的插件实现 volumePluginName := unknownVolumePlugin volumePlugin, err := og.volumePluginMgr.FindPluginBySpec(volumeToMount.VolumeSpec) mountVolumeFunc := func() (error, error) { //获取插件实现 volumePlugin, err := og.volumePluginMgr.FindPluginBySpec(volumeToMount.VolumeSpec) //检查亲缘性 affinityErr := checkNodeAffinity(og, volumeToMount) ...... //生成一个 Mounter，这里是插件的通用接口 volumeMounter, newMounterErr := volumePlugin.NewMounter( volumeToMount.VolumeSpec, volumeToMount.Pod, volume.VolumeOptions{}) //如果有Attacher，先执行 attacher attachableVolumePlugin, _ := og.volumePluginMgr.FindAttachablePluginBySpec(volumeToMount.VolumeSpec) var volumeAttacher volume.Attacher if attachableVolumePlugin != nil { volumeAttacher, _ = attachableVolumePlugin.NewAttacher() } // 如果有设备挂载，处理设备挂载 deviceMountableVolumePlugin, _ := og.volumePluginMgr.FindDeviceMountablePluginBySpec(volumeToMount.VolumeSpec) var volumeDeviceMounter volume.DeviceMounter if deviceMountableVolumePlugin != nil { volumeDeviceMounter, _ = deviceMountableVolumePlugin.NewDeviceMounter() } //权限之类的 var fsGroup *int64 var fsGroupChangePolicy *v1.PodFSGroupChangePolicy if podSc := volumeToMount.Pod.Spec.SecurityContext; podSc != nil { if podSc.FSGroup != nil { fsGroup = podSc.FSGroup } if podSc.FSGroupChangePolicy != nil { fsGroupChangePolicy = podSc.FSGroupChangePolicy } } //这就是本机的待挂载的路径 devicePath := volumeToMount.DevicePath if volumeAttacher != nil { //如果需要 Attach 到本机的卷，那么实际 mount 的路径是 attach 之后的路径 devicePath, err = volumeAttacher.WaitForAttach( volumeToMount.VolumeSpec, devicePath, volumeToMount.Pod, waitForAttachTimeout) ....... } if volumeDeviceMounter != nil { //获取设备挂载路径， deviceMountPath, err := volumeDeviceMounter.GetDeviceMountPath(volumeToMount.VolumeSpec) // 挂载设备 err = volumeDeviceMounter.MountDevice( volumeToMount.VolumeSpec, devicePath, deviceMountPath) //更新实际挂载状态 markDeviceMountedErr := actualStateOfWorld.MarkDeviceAsMounted( volumeToMount.VolumeName, devicePath, deviceMountPath) if markDeviceMountedErr != nil { // On failure, return error. Caller will log and retry. return volumeToMount.GenerateError(&quot;MountVolume.MarkDeviceAsMounted failed&quot;, markDeviceMountedErr) } ...... } if og.checkNodeCapabilitiesBeforeMount { if canMountErr := volumeMounter.CanMount(); canMountErr != nil { err = fmt.Errorf( &quot;Verify that your node machine has the required components before attempting to mount this volume type. %s&quot;, canMountErr) return volumeToMount.GenerateError(&quot;MountVolume.CanMount failed&quot;, err) } } // 执行挂载操作 mountErr := volumeMounter.SetUp(volume.MounterArgs{ FsUser: ioutil.FsUserFrom(volumeToMount.Pod), FsGroup: fsGroup, DesiredSize: volumeToMount.DesiredSizeLimit, FSGroupChangePolicy: fsGroupChangePolicy, }) ...... //后续一堆处理，修正实际的挂载状态 } 5. plugins 从上述代码来看，挂载的操作，是交给了插件去真正执行的，插件的接口描述如下 //volume/volume.go type Volume interface { //准备把卷挂载到 Pod 的哪个路径 GetPath() string MetricsProvider } //插件接口 type Mounter interface { // Uses Interface to provide the path for Docker binds. Volume //是否可以挂载, 主要用于校验一下 CanMount() error //执行挂载操作 SetUp(mounterArgs MounterArgs) error //执行挂载操作，不同的是，可以指定一个目录去挂载 SetUpAt(dir string, mounterArgs MounterArgs) error //获取这个 mounter 插件的一堆属性，必须在挂载之后才能调用 GetAttributes() Attributes } kubernetes提供了许多内置的插件，比如本地文件，nfs，云存储提供商等等。 找个最简单的插件来看下怎么实现的吧。 这里选 local 这个挂载器，把本机文件挂载到 pod 中去。 //volume/local/local.go // SetUp bind mounts the directory to the volume path func (m *localVolumeMounter) SetUp(mounterArgs volume.MounterArgs) error { return m.SetUpAt(m.GetPath(), mounterArgs) } //获取要挂载的本地目录 func (l *localVolume) GetPath() string { return l.plugin.host.GetPodVolumeDir(l.podUID, utilstrings.EscapeQualifiedName(localVolumePluginName), l.volName) } 首先获取本机要挂载到Pod 里的路径，最终一顿猛如虎的操作之后，得到的最终路径为 /var/lib/kubelet/pods/pod的 UID/volumes/插件名/卷名 当前 local 的卷名就是：kubernetes.io/local-volume, 具体来看是如何挂载的 //volume/local/local.go func (m *localVolumeMounter) SetUpAt(dir string, mounterArgs volume.MounterArgs) error { m.plugin.volumeLocks.LockKey(m.globalPath) defer m.plugin.volumeLocks.UnlockKey(m.globalPath) ...... //如果没有挂载点，返回 notMnt, err := mount.IsNotMountPoint(m.mounter, dir) ...... //设置挂载参数，这里指定的是 bind 技术 options := []string{&quot;bind&quot;} if m.readOnly { options = append(options, &quot;ro&quot;) } mountOptions := util.JoinMountOptions(options, m.mountOptions) //获取本机的绝对路径 globalPath := util.MakeAbsolutePath(runtime.GOOS, m.globalPath) //执行挂载 err = m.mounter.Mount(globalPath, dir, &quot;&quot;, mountOptions) ...... } 最终交由了mount_linux.go来进行 Mount操作 . //vendor/k8s.io/utils/mount/mount_linux.go func (mounter *Mounter) MountSensitive(source string, target string, fstype string, options []string, sensitiveOptions []string) error { // Path to mounter binary if containerized mounter is needed. Otherwise, it is set to empty. // All Linux distros are expected to be shipped with a mount utility that a support bind mounts. mounterPath := &quot;&quot; bind, bindOpts, bindRemountOpts, bindRemountOptsSensitive := MakeBindOptsSensitive(options, sensitiveOptions) //如果采用了 bind 技术 if bind { //直接执行了exe.Command执行 mount --bind err := mounter.doMount(mounterPath, defaultMountCommand, source, target, fstype, bindOpts, bindRemountOptsSensitive) if err != nil { return err } return mounter.doMount(mounterPath, defaultMountCommand, source, target, fstype, bindRemountOpts, bindRemountOptsSensitive) } // The list of filesystems that require containerized mounter on GCI image cluster fsTypesNeedMounter := map[string]struct{}{ &quot;nfs&quot;: {}, &quot;glusterfs&quot;: {}, &quot;ceph&quot;: {}, &quot;cifs&quot;: {}, } if _, ok := fsTypesNeedMounter[fstype]; ok { mounterPath = mounter.mounterPath } return mounter.doMount(mounterPath, defaultMountCommand, source, target, fstype, options, sensitiveOptions) } //vendor/k8s.io/utils/mount/mount_linux.go func (mounter *Mounter) doMount(mounterPath string, mountCmd string, source string, target string, fstype string, options []string, sensitiveOptions []string) error { mountArgs, mountArgsLogStr := MakeMountArgsSensitive(source, target, fstype, options, sensitiveOptions) if len(mounterPath) &gt; 0 { mountArgs = append([]string{mountCmd}, mountArgs...) mountArgsLogStr = mountCmd + &quot; &quot; + mountArgsLogStr mountCmd = mounterPath } if mounter.withSystemd { mountCmd, mountArgs, mountArgsLogStr = AddSystemdScopeSensitive(&quot;systemd-run&quot;, target, mountCmd, mountArgs, mountArgsLogStr) } else { } command:= exec.Command(mountCmd, mountArgs...) output, err := command.CombinedOutput() if err != nil { klog.Errorf(&quot;Mount failed: %v\\nMounting command: %s\\nMounting arguments: %s\\nOutput: %s\\n&quot;, err, mountCmd, mountArgsLogStr, string(output)) return fmt.Errorf(&quot;mount failed: %v\\nMounting command: %s\\nMounting arguments: %s\\nOutput: %s&quot;, err, mountCmd, mountArgsLogStr, string(output)) } return err } 最终执行的命令是： mount —bind 源 目的 当然了，除了本地 local 插件之外，k8s还内置了需要插件，比如EmptyDir, ConfigMap,Secret，NFS 等等。实现方式大同小异. 6. 总结 k8s在卷管理方面大致需要以下几个组件 Volume Manager 是卷管理的驱动入口，负责调谐 pod 和 volume，把pod 的预期卷信息，转化为实际的卷挂载。 Volume plugins 一个插件体系，提供了扩展接口，包含了各类存储提供者的plugins实现 pv/pvc Controller 运行在 Master 上的组件，主要做provision/delete, 其他文章再介绍 Attach/Detach Controller 运行在 master 上，主要做一些块设备的Attach和Detach， 比如一些设备GCE 等，必须先Attach到本机节点，之后才能被使用 卷挂载的主要流程大概是这样的 用户创建 Pod，提供一个 PVC 信息 Pod 被分配到节点 NodeA kubelet等待 Volume Manager 挂载完成 (还有其他的一堆等待，比如网络) PV Controller 创建持久化卷并在系统中创建 PV 对象，以及绑定 PVC Attach/Detach Controller 通过插件实现块设备的挂载 Volume Manager 将本机 node 节点的目录，挂载到 Pod中。执行的是mount命令。 kubelet 在启动容器的时候， 通过 CRI 接口，将参数传递给 CRI 的实现者，比如 docker，docker 执行docker -v 把 Pod 的卷信息，再次通过 bind mount 技术，映射到容器中去 Pod绑定 Volume 是把本地目录挂载到 Pod 中，并没有给容器 容器绑定卷，是在启动容器StartContainer的时候，把 Pod 的卷信息 bind 给容器的 ","link":"http://kzltime.cn/post/volume-manager/"}]}